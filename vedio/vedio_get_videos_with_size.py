#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ–éŸ³ç”¨æˆ·ä½œå“URLè·å–å·¥å…· (å¢å¼ºç‰ˆ)
åŠŸèƒ½ï¼šæ ¹æ®æŠ–éŸ³ç”¨æˆ·ä¸»é¡µé“¾æ¥ï¼Œè·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰ä½œå“è§†é¢‘URLå’Œæ–‡ä»¶å¤§å°
"""

import os
import sys
import json
import time
import requests
from datetime import datetime
from urllib.parse import urlparse, unquote
from typing import List, Dict, Optional, Tuple

# å¯¼å…¥æ‰€éœ€çš„æ¨¡å—
try:
    # å¯¼å…¥æœ¬åœ°çš„æŠ–éŸ³æ¨¡å—
    import douyin_request as request
    import douyin_cookies as cookies  
    import douyin_util as util
except ImportError:
    print("âŒ æ‰¾ä¸åˆ°æ‰€éœ€çš„æ¨¡å—ï¼Œå°è¯•ä½¿ç”¨ç›¸å¯¹è·¯å¾„å¯¼å…¥...")
    sys.path.insert(0, os.path.dirname(__file__))
    try:
        import douyin_request as request
        import douyin_cookies as cookies  
        import douyin_util as util
    except ImportError:
        print("âŒ å¯¼å…¥æ¨¡å—å¤±è´¥ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨")
        sys.exit(1)

# å¯¼å…¥æ‰€éœ€å‡½æ•°
Request = request.Request
get_cookie_dict = cookies.get_cookie_dict
str_to_path = util.str_to_path
url_redirect = util.url_redirect


class DouyinVideoURLGetter:
    """æŠ–éŸ³ç”¨æˆ·ä½œå“URLè·å–å™¨ (å¢å¼ºç‰ˆ)"""
    
    def __init__(self, cookie: str = ''):
        """
        åˆå§‹åŒ–è·å–å™¨
        
        Args:
            cookie: Cookieå­—ç¬¦ä¸²æˆ–é…ç½®
        """
        self.cookie = cookie
        self.request = Request(cookie)
        self.results = []
        self.has_more = True
        
        # è¯·æ±‚å¤´è®¾ç½®
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": "https://www.douyin.com/",
            "Range": "bytes=0-0"  # åªè·å–å¤´éƒ¨ä¿¡æ¯
        }
        
        # è¯·æ±‚è¶…æ—¶è®¾ç½®
        self.timeout = (5, 10)  # (è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
        
    def extract_user_id_from_url(self, url: str) -> Optional[str]:
        """ä»æŠ–éŸ³é“¾æ¥ä¸­æå–ç”¨æˆ·ID"""
        try:
            # å¤„ç†çŸ­é“¾æ¥é‡å®šå‘
            if 'v.douyin.com' in url:
                url = url_redirect(url)
            
            # æå–sec_user_id
            if '/user/' in url:
                path = urlparse(url).path
                user_id = path.split('/user/')[-1].split('?')[0]
                return user_id
            else:
                print("âŒ æ— æ³•ä»URLä¸­æå–ç”¨æˆ·IDï¼Œè¯·æ£€æŸ¥é“¾æ¥æ ¼å¼")
                return None
                
        except Exception as e:
            print(f"âŒ URLè§£æå¤±è´¥: {e}")
            return None
    
    def get_video_size(self, url: str) -> int:
        """
        è·å–è§†é¢‘æ–‡ä»¶å¤§å°
        
        Args:
            url: è§†é¢‘URL
            
        Returns:
            è§†é¢‘å¤§å°ï¼ˆå­—èŠ‚æ•°ï¼‰
        """
        try:
            # ä»…å‘é€HEADè¯·æ±‚è·å–æ–‡ä»¶å¤§å°
            response = requests.head(
                url, 
                headers=self.headers, 
                timeout=self.timeout,
                allow_redirects=True
            )
            
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚æˆåŠŸ
            if response.status_code == 200:
                # å°è¯•ä»Content-Lengthå¤´è·å–æ–‡ä»¶å¤§å°
                content_length = response.headers.get('Content-Length')
                if content_length:
                    return int(content_length)
            
            # å¦‚æœHEADè¯·æ±‚å¤±è´¥æˆ–æ²¡æœ‰Content-Lengthï¼Œå°è¯•å‘é€Rangeè¯·æ±‚
            range_headers = self.headers.copy()
            range_headers["Range"] = "bytes=0-1"  # åªè¯·æ±‚å‰ä¸¤ä¸ªå­—èŠ‚
            
            response = requests.get(
                url, 
                headers=range_headers, 
                timeout=self.timeout,
                stream=True
            )
            
            # æ£€æŸ¥Content-Rangeå¤´
            if response.status_code == 206:
                content_range = response.headers.get('Content-Range')
                if content_range:
                    # Content-Rangeæ ¼å¼: bytes 0-1/1234567
                    total_size = content_range.split('/')[-1]
                    if total_size.isdigit():
                        return int(total_size)
            
            # å°è¯•æœ€åä¸€ç§æ–¹æ³•ï¼šä½¿ç”¨requestsçš„streamåŠŸèƒ½è·å–æ€»å¤§å°
            response = requests.get(
                url, 
                headers=self.headers, 
                timeout=self.timeout,
                stream=True
            )
            
            if 'Content-Length' in response.headers:
                return int(response.headers['Content-Length'])
            
            # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›-1è¡¨ç¤ºæ— æ³•è·å–å¤§å°
            print(f"âš ï¸ æ— æ³•è·å–è§†é¢‘å¤§å°: {url}")
            return -1
            
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ è·å–è§†é¢‘å¤§å°æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")
            return -1
        except Exception as e:
            print(f"âš ï¸ è·å–è§†é¢‘å¤§å°å¤±è´¥: {e}")
            return -1
    
    def get_formatted_size(self, size_in_bytes: int) -> str:
        """
        å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼
        
        Args:
            size_in_bytes: å­—èŠ‚æ•°
            
        Returns:
            æ ¼å¼åŒ–åçš„å¤§å°å­—ç¬¦ä¸²ï¼Œå¦‚ "10.5 MB"
        """
        if size_in_bytes < 0:
            return "æœªçŸ¥å¤§å°"
            
        # å­—èŠ‚åˆ°æ›´å¤§å•ä½çš„è½¬æ¢
        units = ["B", "KB", "MB", "GB", "TB"]
        size = float(size_in_bytes)
        unit_index = 0
        
        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1
            
        # æ ¼å¼åŒ–è¾“å‡ºï¼Œå°æ•°ç‚¹åä¿ç•™2ä½
        return f"{size:.2f} {units[unit_index]}"
    
    def get_user_videos(self, sec_user_id: str, max_videos: int = 0) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘ä½œå“URL"""
        print(f"ğŸ“¥ å¼€å§‹è·å–ç”¨æˆ· {sec_user_id} çš„è§†é¢‘ä½œå“...")
        
        max_cursor = 0
        retry_count = 0
        max_retry = 5
        all_videos = []
        
        while self.has_more:
            try:
                # æ„é€ è¯·æ±‚å‚æ•°
                uri = '/aweme/v1/web/aweme/post/'
                params = {
                    "publish_video_strategy_type": 2,
                    "max_cursor": max_cursor,
                    "locate_query": False,
                    'show_live_replay_strategy': 1,
                    'need_time_list': 0,
                    'time_list_query': 0,
                    'whale_cut_token': '',
                    'count': 18,
                    "sec_user_id": sec_user_id
                }
                
                # å‘é€è¯·æ±‚
                resp = self.request.getJSON(uri, params)
                if not resp:
                    retry_count += 1
                    print(f"âš ï¸ è¯·æ±‚å¤±è´¥ï¼Œç¬¬ {retry_count}/{max_retry} æ¬¡é‡è¯•...")
                    if retry_count >= max_retry:
                        print("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢è·å–")
                        break
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                
                # é‡ç½®é‡è¯•è®¡æ•°
                retry_count = 0
                
                # è·å–ä¸‹ä¸€é¡µçš„cursor
                max_cursor = resp.get('max_cursor', 0)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                self.has_more = resp.get('has_more', 0)
                
                # æå–è§†é¢‘åˆ—è¡¨
                aweme_list = resp.get('aweme_list', [])
                if not aweme_list:
                    print("â„¹ï¸ æœªæ‰¾åˆ°æ›´å¤šä½œå“")
                    break
                
                # å¤„ç†è§†é¢‘ä¿¡æ¯
                for item in aweme_list:
                    # æå–è§†é¢‘ä¿¡æ¯
                    video_info = self.extract_video_info(item)
                    if video_info:
                        # è·å–è§†é¢‘å¤§å°
                        video_size = self.get_video_size(video_info['url'])
                        video_info['size_bytes'] = video_size
                        video_info['size_formatted'] = self.get_formatted_size(video_size)
                        
                        all_videos.append(video_info)
                        print(f"âœ… è·å–åˆ°è§†é¢‘: {video_info['desc']} [ID: {video_info['id']}, å¤§å°: {video_info['size_formatted']}]")
                
                # æ˜¾ç¤ºè¿›åº¦
                print(f"ğŸ”„ å·²è·å– {len(all_videos)} ä¸ªè§†é¢‘, æ˜¯å¦ç»§ç»­: {self.has_more}")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¸Šé™
                if max_videos > 0 and len(all_videos) >= max_videos:
                    print(f"ğŸ›‘ å·²è¾¾åˆ°è®¾å®šçš„æœ€å¤§è§†é¢‘æ•°é‡ {max_videos}")
                    break
                
                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1)
                
            except Exception as e:
                print(f"âŒ è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
                retry_count += 1
                if retry_count >= max_retry:
                    print("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢è·å–")
                    break
                time.sleep(2)
        
        print(f"âœ… è·å–å®Œæˆï¼Œå…±è·å–åˆ° {len(all_videos)} ä¸ªè§†é¢‘ä½œå“")
        self.results = all_videos
        return all_videos
    
    def extract_video_info(self, item: Dict) -> Optional[Dict]:
        """ä»ä½œå“æ•°æ®ä¸­æå–è§†é¢‘ä¿¡æ¯"""
        try:
            # å¤„ç†è§†é¢‘ç±»å‹
            _type = item.get('aweme_type', item.get('awemeType'))
            
            # åªæå–è§†é¢‘ç±»å‹çš„ä½œå“
            if _type <= 66 or _type in [69, 107]:  # è§†é¢‘ç±»å‹
                # æå–åŸºæœ¬ä¿¡æ¯
                video_info = {
                    'id': item.get('aweme_id', item.get('awemeId', '')),
                    'desc': item.get('desc', 'æ— æ ‡é¢˜'),
                    'create_time': item.get('create_time', 0),
                    'type': _type,
                    'duration': item['video'].get('duration', 0),  # è§†é¢‘æ—¶é•¿(ms)
                }
                
                # æå–è§†é¢‘ä¸‹è½½åœ°å€
                play_addr = item['video'].get('play_addr')
                if play_addr:
                    video_info['url'] = play_addr['url_list'][-1]
                else:
                    video_info['url'] = item['download']['urlList'][-1].replace('watermark=1', 'watermark=0')
                
                # æå–å°é¢å›¾
                cover = item['video'].get('cover')
                if isinstance(cover, dict):
                    video_info['cover'] = cover['url_list'][-1]
                else:
                    video_info['cover'] = f"https:{item['video']['dynamicCover']}"
                
                # ç»Ÿè®¡ä¿¡æ¯
                stats = item.get('statistics', {})
                video_info['play_count'] = stats.get('play_count', 0)
                video_info['digg_count'] = stats.get('digg_count', 0)  # ç‚¹èµæ•°
                video_info['comment_count'] = stats.get('comment_count', 0)
                video_info['share_count'] = stats.get('share_count', 0)
                video_info['download_count'] = stats.get('download_count', 0)
                
                # å°è¯•è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
                if 'width' in item['video'] and 'height' in item['video']:
                    video_info['width'] = item['video']['width']
                    video_info['height'] = item['video']['height']
                    video_info['resolution'] = f"{video_info['width']}x{video_info['height']}"
                
                return video_info
            else:
                # ä¸æ˜¯è§†é¢‘ç±»å‹ï¼Œè·³è¿‡
                return None
                
        except Exception as e:
            print(f"âŒ æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_videos_from_user_url(self, user_url: str, max_videos: int = 0) -> List[Dict]:
        """æ ¹æ®ç”¨æˆ·ä¸»é¡µURLè·å–è§†é¢‘ä½œå“åˆ—è¡¨"""
        print(f"ğŸ” åˆ†æç”¨æˆ·é“¾æ¥: {user_url}")
        
        # æå–ç”¨æˆ·ID
        sec_user_id = self.extract_user_id_from_url(user_url)
        if not sec_user_id:
            return []
        
        print(f"âœ… æå–åˆ°ç”¨æˆ·ID: {sec_user_id}")
        
        # è·å–ç”¨æˆ·è§†é¢‘
        return self.get_user_videos(sec_user_id, max_videos)
    
    def save_to_file(self, filename: str = "video_urls.json"):
        """ä¿å­˜è§†é¢‘ä¿¡æ¯åˆ°æ–‡ä»¶"""
        if not self.results:
            print("âŒ æ²¡æœ‰è§†é¢‘æ•°æ®å¯ä¿å­˜")
            return False
        
        try:
            # å‡†å¤‡è¾“å‡ºæ•°æ®
            output_data = {
                "extraction_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "total_videos": len(self.results),
                "videos": self.results
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å·²ä¿å­˜è§†é¢‘ä¿¡æ¯åˆ°: {filename}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False


def load_cookie_from_config(cookie_config_file: str = 'config/cookie.json') -> str:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½Cookie"""
    try:
        if not os.path.exists(cookie_config_file):
            print(f"âš ï¸ Cookieé…ç½®æ–‡ä»¶ {cookie_config_file} ä¸å­˜åœ¨")
            return ''
        
        with open(cookie_config_file, 'r', encoding='utf-8') as f:
            cookie_json = json.load(f)
            
        if isinstance(cookie_json, dict):
            # å¦‚æœæ˜¯JSONå¯¹è±¡ï¼Œå°è¯•æå–cookieå­—æ®µ
            cookie = cookie_json.get('cookie', '')
        else:
            # å‡è®¾æ˜¯ç›´æ¥çš„cookieå­—ç¬¦ä¸²
            cookie = str(cookie_json)
            
        if cookie:
            print("âœ… ä»é…ç½®æ–‡ä»¶è¯»å–åˆ°cookie")
        else:
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„cookie")
            
        return cookie
            
    except Exception as e:
        print(f"âŒ è¯»å–cookieé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return ''


def read_urls_from_config(config_file: str = 'urls_config.txt') -> List[str]:
    """ä»é…ç½®æ–‡ä»¶è¯»å–URLåˆ—è¡¨"""
    urls = []
    
    try:
        if not os.path.exists(config_file):
            print(f"âŒ é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨")
            return urls
        
        with open(config_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        if not content:
            print(f"âŒ é…ç½®æ–‡ä»¶ {config_file} ä¸ºç©º")
            return urls
        
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
        lines = content.replace('\r\n', '\n').replace('\r', '\n').split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                continue
            
            # æ”¯æŒå¤šä¸ªURLåœ¨ä¸€è¡Œï¼ˆç”¨é€—å·ã€åˆ†å·ã€ç©ºæ ¼åˆ†éš”ï¼‰
            line_urls = []
            for sep in [',', ';', ' ', '\t']:
                if sep in line:
                    line_urls = [url.strip() for url in line.split(sep) if url.strip()]
                    break
            
            if not line_urls:
                line_urls = [line]
            
            for url in line_urls:
                if url and ('douyin.com' in url or 'v.douyin.com' in url):
                    urls.append(url)
                elif url:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆé“¾æ¥: {url}")
        
        print(f"âœ… ä»é…ç½®æ–‡ä»¶è¯»å–åˆ° {len(urls)} ä¸ªæœ‰æ•ˆé“¾æ¥")
        return urls
        
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return urls


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æŠ–éŸ³ç”¨æˆ·ä½œå“URLè·å–å·¥å…· (å¢å¼ºç‰ˆ)")
    print("-" * 50)
    print("åŠŸèƒ½ï¼šè·å–æŠ–éŸ³ç”¨æˆ·ä½œå“çš„URLå’Œæ–‡ä»¶å¤§å°")
    print("-" * 50)
    
    # åŠ è½½Cookie
    cookie = load_cookie_from_config()
    if not cookie:
        print("âš ï¸ æœªæ‰¾åˆ°cookieé…ç½®ï¼Œå¯èƒ½ä¼šå¯¼è‡´è·å–å¤±è´¥")
    
    # è¯»å–URLé…ç½®
    urls = read_urls_from_config()
    if not urls:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„URLï¼Œç¨‹åºé€€å‡º")
        return
    
    # åˆ›å»ºè§†é¢‘URLè·å–å™¨
    video_getter = DouyinVideoURLGetter(cookie)
    
    # è®¾ç½®æœ€å¤§è·å–æ•°é‡ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
    max_videos = 0
    
    # å¤„ç†æ¯ä¸ªç”¨æˆ·é“¾æ¥
    for i, url in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}] å¼€å§‹å¤„ç†é“¾æ¥: {url}")
        print("-" * 50)
        
        # è·å–è§†é¢‘åˆ—è¡¨
        videos = video_getter.get_videos_from_user_url(url, max_videos)
        
        if videos:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"video_urls_with_size_{timestamp}_{i}.json"
            
            # ä¿å­˜è§†é¢‘ä¿¡æ¯
            video_getter.save_to_file(filename)
            
            # æ‰“å°è§†é¢‘ä¿¡æ¯æ±‡æ€»
            print("\nğŸ“‹ è§†é¢‘ä¿¡æ¯æ±‡æ€»:")
            for j, video in enumerate(videos, 1):
                print(f"{j}. {video['desc']} - {video.get('size_formatted', 'æœªçŸ¥å¤§å°')}")
        else:
            print("âŒ æœªè·å–åˆ°è§†é¢‘æ•°æ®")
        
        # æ·»åŠ å»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        if i < len(urls):
            print("\nâ±ï¸ ç­‰å¾…5ç§’åå¤„ç†ä¸‹ä¸€ä¸ªé“¾æ¥...")
            time.sleep(5)
    
    print("\nâœ… æ‰€æœ‰é“¾æ¥å¤„ç†å®Œæˆ!")


if __name__ == "__main__":
    main()
